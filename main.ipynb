{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from PIL import Image\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class OpenAIModel:\n",
    "    def __init__(self):\n",
    "        api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY is not set in the environment\")\n",
    "        self.model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    \n",
    "    def complete(self, messages):\n",
    "        return self.model.invoke(messages)\n",
    "\n",
    "\n",
    "class GeminiModel:\n",
    "    parser = StrOutputParser()\n",
    "    def __init__(self, temperature = 0.7, max_output_tokens = None, top_p = None, top_k = None):\n",
    "        api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "        if not api_key:\n",
    "            raise ValueError(\"GEMINI_API_KEY is not set in the environment\")\n",
    "        self.model = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=api_key,\n",
    "                                            temperature = temperature, max_output_tokens = max_output_tokens, top_p = top_p, top_k = top_k)\n",
    "        self.vision_model = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\", google_api_key=api_key,\n",
    "                                                   temperature = temperature, max_output_tokens = max_output_tokens, top_p = top_p, top_k = top_k)\n",
    "        self.string_chain = self.model | self.parser\n",
    "        self.embeddings = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/embedding-001\", \n",
    "            google_api_key=api_key\n",
    "        )\n",
    "\n",
    "    \n",
    "    def _set_prompt(self, promptTemplate: ChatPromptTemplate):\n",
    "        self.prompt_chain = promptTemplate | self.model | self.parser\n",
    "    \n",
    "    def complete(self, messages):\n",
    "        return self.model.invoke(messages)\n",
    "    \n",
    "    def getTextResponse(self, messages):\n",
    "        return self.string_chain.invoke(messages)\n",
    "    \n",
    "    def getEmbedding(self, text):\n",
    "        return self.embeddings.embed_query(\"hello, world!\")\n",
    "    \n",
    "    def getPromptResponse(self, data: dict):\n",
    "        if not self.prompt_chain:\n",
    "            raise ValueError(\"Prompt template is not set\")\n",
    "        return self.prompt_chain.invoke(data)\n",
    "    \n",
    "    def chatWithImage(self, imageData: str | Image.Image, prompt: str, messages = []):\n",
    "        \"\"\"Accepts image data with prompt for completion\n",
    "        \n",
    "            Parameters\n",
    "            ----------\n",
    "            imageData : str\n",
    "                the data to image. Can be a URL or base64 encoded image or a PIL Image object or\n",
    "                a filepath.\n",
    "            prompt : str\n",
    "                The text prompt to accompany the text\n",
    "            messages : list\n",
    "                The list of messages in the previous conversation\n",
    "        \"\"\"\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "                },  # You can optionally provide text parts\n",
    "                {\"type\": \"image_url\", \"image_url\": imageData},\n",
    "            ]\n",
    "        )\n",
    "        return self.vision_model.invoke([*messages, message]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Translate the following from English into Italian: hi!\"),\n",
    "]\n",
    "\n",
    "model = GeminiModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A girl is sitting on a bed in her bedroom. She is looking out the window at the rain. The window is decorated with stars and flowers. The bed is covered in pillows and a blanket. There is a laptop on the bed. The girl is wearing a blue shirt and jeans. She has her hair in a ponytail. She is holding a cup of coffee.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.chatWithImage(\n",
    "    imageData=\"videos/screenshot.jpg\",\n",
    "    prompt=\"Describe what's happening in this image.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt tempaltes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# way 1\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"user\", \"Translate the following from English to {language}\"), (\"user\", \"{text}\")]\n",
    ")\n",
    "result = prompt_template.invoke({\n",
    "    \"language\": \"Italian\",\n",
    "    \"text\": \"hi!\"\n",
    "})\n",
    "messages = result.to_messages()\n",
    "model.getTextResponse(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciao!'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# way 2\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"user\", \"Translate the following from English to {language}\"), MessagesPlaceholder(\"messages\")]\n",
    ")\n",
    "model._set_prompt(prompt_template)\n",
    "model.getPromptResponse({\n",
    "    \"language\": \"Italian\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"hi!\")\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
